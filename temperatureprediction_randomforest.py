# -*- coding: utf-8 -*-
"""TemperaturePrediction_RandomForest.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/19kTaTWE98Cpx_y7BWJJyjJ7vc_DvB3Nm
"""

from google.colab import files

# Uploading my kaggle.json file
files.upload()

# Im Creating a directory for the Kaggle API credentials
!mkdir -p ~/.kaggle

# Moving the uploaded kaggle.json file into the Kaggle folder
!mv kaggle.json ~/.kaggle/

# Seting the permissions for the kaggle.json file
!chmod 600 ~/.kaggle/kaggle.json

# Downloading the dataset using Kaggle API
!kaggle datasets download -d sudalairajkumar/daily-temperature-of-major-cities

# Unzipping the dataset for me to use now
!unzip daily-temperature-of-major-cities.zip

import pandas as pd

# Loading the dataset
df = pd.read_csv('city_temperature.csv')

# Checking the original size of the dataset
print("Original dataset size:", df.shape)

# Sample only 10% of the dataset to reduce memory usage (Basically using only 100k of the data)
df = df.sample(frac=0.1, random_state=42)

# Checking the new size of the dataset
print("Reduced dataset size:", df.shape)

# Inspecting the first few rows to check the data
df.head()

# Dropping 'State', 'Year', and 'Day' columns, as we don't need them for the model
df = df.drop(columns=['State', 'Year', 'Day'])

# Filtering out erroneous temperature values (e.g., AvgTemperature < -50)
df = df[df['AvgTemperature'] > -50]

# Extracting the 'Month' and keep it as is (it’s already numeric)
# No need to convert 'Month' using pd.to_datetime()
df['Month'] = df['Month']

# Extract 'DayOfWeek' from the available columns
df['DayOfWeek'] = pd.to_datetime(df['Month'], errors='coerce').dt.dayofweek  # Derived feature

# Dropping rows with missing data, just to be safe
df = df.dropna()

# Check the cleaned dataset
df.head()

# One-hot encode categorical columns 'Region', 'Country', and 'City'
df = pd.get_dummies(df, columns=['Region', 'Country', 'City'], drop_first=True)

# Check the final dataset's info to ensure all columns are numeric
df.info()

# Check the current shape of the data
print("Final dataset shape after encoding:", df.shape)

# Define features (X) and target (y)
X = df.drop(columns=['AvgTemperature'])  # The target is 'AvgTemperature', so we drop it from the features
y = df['AvgTemperature']

# Check the shapes of X and y
print("X shape:", X.shape)
print("y shape:", y.shape)

from sklearn.model_selection import train_test_split

# Split the dataset into 80% training and 20% testing sets
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Check the shapes of the training and test sets
print(X_train.shape, X_test.shape, y_train.shape, y_test.shape)

from sklearn.ensemble import RandomForestRegressor
from sklearn.metrics import mean_squared_error, r2_score

# Create a Random Forest model with fewer trees and limited depth
rf_model = RandomForestRegressor(n_estimators=10, max_depth=10, random_state=42)

# Train the model on the training data
rf_model.fit(X_train, y_train)

# Make predictions on both the training and test sets
y_train_pred = rf_model.predict(X_train)
y_test_pred = rf_model.predict(X_test)

# Evaluate performance on the training set
train_mse = mean_squared_error(y_train, y_train_pred)
train_r2 = r2_score(y_train, y_train_pred)

# Evaluate performance on the test set
test_mse = mean_squared_error(y_test, y_test_pred)
test_r2 = r2_score(y_test, y_test_pred)

# Print the performance metrics
print('Random Forest Regression Performance:')
print(f'Train MSE: {train_mse}')
print(f'Train R²: {train_r2}')
print(f'Test MSE: {test_mse}')
print(f'Test R²: {test_r2}')

import matplotlib.pyplot as plt

# Create a scatter plot to visualize the predicted values vs the actual values
plt.figure(figsize=(10, 6))
plt.scatter(y_test, y_test_pred, alpha=0.5)
plt.plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], 'r--', lw=2)  # Identity line (y=x)
plt.xlabel('Actual AvgTemperature')
plt.ylabel('Predicted AvgTemperature')
plt.title('Actual vs. Predicted AvgTemperature')
plt.show()

# Create a line plot for a small sample (for better visualization)
plt.figure(figsize=(10, 6))
plt.plot(y_test.values[:100], label='Actual AvgTemperature', marker='o')
plt.plot(y_test_pred[:100], label='Predicted AvgTemperature', marker='x')
plt.xlabel('Sample Index')
plt.ylabel('AvgTemperature')
plt.title('Actual vs. Predicted AvgTemperature (Sample)')
plt.legend()
plt.show()

# Save the predictions to an Excel file
train_results = pd.DataFrame({'Actual': y_train, 'Predicted': y_train_pred})
test_results = pd.DataFrame({'Actual': y_test, 'Predicted': y_test_pred})

# Save to Excel
with pd.ExcelWriter('random_forest_results.xlsx', engine='openpyxl') as writer:
    train_results.to_excel(writer, sheet_name='Train Results', index=False)
    test_results.to_excel(writer, sheet_name='Test Results', index=False)

from google.colab import files
files.download('random_forest_results.xlsx')